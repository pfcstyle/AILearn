{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    keras import layers\n",
    "import  numpy as np\n",
    "import  time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(root, filename, name2label):\n",
    "    # root:数据集根目录\n",
    "    # filename:csv文件名\n",
    "    # name2label:类别名编码表\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys():\n",
    "            # 'pokemon\\\\mewtwo\\\\00001.png\n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "\n",
    "        # 1167, 'pokemon\\\\bulbasaur\\\\00000000.png'\n",
    "        print(len(images), images)\n",
    "\n",
    "        random.shuffle(images)\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  # 'pokemon\\\\bulbasaur\\\\00000000.png'\n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                # 'pokemon\\\\bulbasaur\\\\00000000.png', 0\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "\n",
    "    # read from csv file\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            # 'pokemon\\\\bulbasaur\\\\00000000.png', 0\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_pokemon(root, mode='train'):\n",
    "    # 创建数字编码表\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # 给每个类别编码一个数字\n",
    "        name2label[name] = len(name2label.keys())\n",
    "\n",
    "    # 读取Label信息\n",
    "    # [file1,file2,], [3,1]\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "\n",
    "    if mode == 'train':  # 60%\n",
    "        images = images[:int(0.6 * len(images))]\n",
    "        labels = labels[:int(0.6 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # 20% = 80%->100%\n",
    "        images = images[int(0.8 * len(images)):]\n",
    "        labels = labels[int(0.8 * len(labels)):]\n",
    "\n",
    "    return images, labels, name2label\n",
    "\n",
    "\n",
    "img_mean = tf.constant([0.485, 0.456, 0.406])\n",
    "img_std = tf.constant([0.229, 0.224, 0.225])\n",
    "def normalize(x, mean=img_mean, std=img_std):\n",
    "    # x: [224, 224, 3]\n",
    "    # mean: [224, 224, 3], std: [3]\n",
    "    x = (x - mean)/std\n",
    "    return x\n",
    "\n",
    "def denormalize(x, mean=img_mean, std=img_std):\n",
    "    x = x * std + mean\n",
    "    return x\n",
    "\n",
    "def preprocess(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "    x = tf.image.resize(x, [244, 244])\n",
    "\n",
    "    # data augmentation, 0~255\n",
    "    # x = tf.image.random_flip_up_down(x)\n",
    "    x= tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_crop(x, [224, 224, 3])\n",
    "\n",
    "    # x: [0,255]=> 0~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    # 0~1 => D(0,1)\n",
    "    x = normalize(x)\n",
    "\n",
    "    y = tf.convert_to_tensor(y)\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "images, labels, table = load_pokemon('pokemon', 'train')\n",
    "# print('images', len(images), images)\n",
    "# print('labels', len(labels), labels)\n",
    "# print(table)\n",
    "\n",
    "# images: string path\n",
    "# labels: number\n",
    "db = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "db = db.shuffle(1000).map(preprocess).batch(32)\n",
    "\n",
    "writter = tf.summary.create_file_writer('logs')\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    # x: [32, 224, 224, 3]\n",
    "    # y: [32]\n",
    "    with writter.as_default():\n",
    "        x = denormalize(x)\n",
    "        tf.summary.image('img',x,step=step,max_outputs=9)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建resnet网络\n",
    "class ResnetBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, channels, strides=1):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "\n",
    "        self.conv1 = layers.Conv2D(channels, 3, strides=strides,\n",
    "                                   padding='same')\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(channels, 3, strides=1,\n",
    "                                   padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "        if strides!=1:\n",
    "            self.down_conv = layers.Conv2D(channels, 1, strides=strides, padding='valid')\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        # 残差连接\n",
    "        if self.strides!=1:\n",
    "            residual = self.down_conv(inputs)\n",
    "            residual = tf.nn.relu(residual)\n",
    "            residual = self.down_bn(residual, training=training)\n",
    "\n",
    "        x = x + residual\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes, initial_filters=16, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.stem = layers.Conv2D(initial_filters, 3, strides=3, padding='valid')\n",
    "\n",
    "        self.blocks = keras.models.Sequential([\n",
    "            ResnetBlock(initial_filters * 2, strides=3),\n",
    "            ResnetBlock(initial_filters * 2, strides=1),\n",
    "            # layers.Dropout(rate=0.5),\n",
    "\n",
    "            ResnetBlock(initial_filters * 4, strides=3),\n",
    "            ResnetBlock(initial_filters * 4, strides=1),\n",
    "\n",
    "            ResnetBlock(initial_filters * 8, strides=2),\n",
    "            ResnetBlock(initial_filters * 8, strides=1),\n",
    "\n",
    "            ResnetBlock(initial_filters * 16, strides=2),\n",
    "            ResnetBlock(initial_filters * 16, strides=1),\n",
    "        ])\n",
    "\n",
    "        self.final_bn = layers.BatchNormalization()\n",
    "        self.avg_pool = layers.GlobalMaxPool2D()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # print('x:',inputs.shape)\n",
    "        out = self.stem(inputs)\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        # print('stem:',out.shape)\n",
    "\n",
    "        out = self.blocks(out, training=training)\n",
    "        # print('res:',out.shape)\n",
    "\n",
    "        out = self.final_bn(out, training=training)\n",
    "        # out = tf.nn.relu(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "\n",
    "        # print('avg_pool:',out.shape)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # print('out:',out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "from    keras.callbacks import EarlyStopping\n",
    "from    keras import layers,optimizers,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  448       \n",
      "                                                                 \n",
      " sequential (Sequential)     (4, 3, 3, 256)            2797280   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  multiple                 1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,800,037\n",
      "Trainable params: 2,794,725\n",
      "Non-trainable params: 5,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "    x = tf.image.resize(x, [244, 244])\n",
    "\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    # x = tf.image.random_flip_up_down(x)\n",
    "    x = tf.image.random_crop(x, [224,224,3])\n",
    "\n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = normalize(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=5)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "batchsz = 256\n",
    "\n",
    "# creat train db\n",
    "images, labels, table = load_pokemon('pokemon',mode='train')\n",
    "db_train = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "db_train = db_train.shuffle(1000).map(preprocess).batch(batchsz)\n",
    "# crate validation db\n",
    "images2, labels2, table = load_pokemon('pokemon',mode='val')\n",
    "db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))\n",
    "db_val = db_val.map(preprocess).batch(batchsz)\n",
    "# create test db\n",
    "images3, labels3, table = load_pokemon('pokemon',mode='test')\n",
    "db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))\n",
    "db_test = db_test.map(preprocess).batch(batchsz)\n",
    "\n",
    "\n",
    "# resnet = keras.Sequential([\n",
    "#     layers.Conv2D(16,5,3),\n",
    "#     layers.MaxPool2D(3,3),\n",
    "#     layers.ReLU(),\n",
    "#     layers.Conv2D(64,5,3),\n",
    "#     layers.MaxPool2D(2,2),\n",
    "#     layers.ReLU(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64),\n",
    "#     layers.ReLU(),\n",
    "#     layers.Dense(5)\n",
    "# ])\n",
    "\n",
    "\n",
    "resnet = ResNet(5)\n",
    "resnet.build(input_shape=(4, 224, 224, 3))\n",
    "resnet.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# resnet.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "#                loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "#                metrics=['accuracy'])\n",
    "# resnet.fit(db_train, validation_data=db_val, validation_freq=1, epochs=100,\n",
    "#            callbacks=[early_stopping])\n",
    "# resnet.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 10s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,026,949\n",
      "Trainable params: 2,565\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\python\\AILearn\\env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 迁移\n",
    "def preprocess(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "    x = tf.image.resize(x, [244, 244])\n",
    "\n",
    "    # x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    x = tf.image.random_crop(x, [224,224,3])\n",
    "\n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = normalize(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=5)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "\n",
    "# creat train db\n",
    "images, labels, table = load_pokemon('pokemon',mode='train')\n",
    "db_train = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "db_train = db_train.shuffle(1000).map(preprocess).batch(batchsz)\n",
    "# crate validation db\n",
    "images2, labels2, table = load_pokemon('pokemon',mode='val')\n",
    "db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))\n",
    "db_val = db_val.map(preprocess).batch(batchsz)\n",
    "# create test db\n",
    "images3, labels3, table = load_pokemon('pokemon',mode='test')\n",
    "db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))\n",
    "db_test = db_test.map(preprocess).batch(batchsz)\n",
    "\n",
    "\n",
    "net = keras.applications.VGG19(weights='imagenet', include_top=False,\n",
    "                               pooling='max')\n",
    "net.trainable = False\n",
    "newnet = keras.Sequential([\n",
    "    net,\n",
    "    layers.Dense(5)\n",
    "])\n",
    "newnet.build(input_shape=(4,224,224,3))\n",
    "newnet.summary()\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "newnet.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "               loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "newnet.fit(db_train, validation_data=db_val, validation_freq=1, epochs=100,\n",
    "           callbacks=[early_stopping])\n",
    "newnet.evaluate(db_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('new_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d58ff1fa528449bec86ac3b87e5b9edec9a0f46f3f9c706338d5512923abfa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
