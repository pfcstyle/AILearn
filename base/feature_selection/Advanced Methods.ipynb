{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
      "64      65          60    70.049958     9375            7            5   \n",
      "682    683         120    70.049958     2887            6            5   \n",
      "960    961          20    50.000000     7207            5            7   \n",
      "1384  1385          50    60.000000     9060            6            5   \n",
      "1100  1101          30    60.000000     8400            2            5   \n",
      "...    ...         ...          ...      ...          ...          ...   \n",
      "763    764          60    82.000000     9430            8            5   \n",
      "835    836          20    60.000000     9600            4            7   \n",
      "1216  1217          90    68.000000     8930            6            5   \n",
      "559    560         120    70.049958     3196            7            5   \n",
      "684    685          60    58.000000    16770            7            5   \n",
      "\n",
      "      YearBuilt  YearRemodAdd  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
      "64         1997          1998         739           0  ...               0   \n",
      "682        1996          1997        1003           0  ...               0   \n",
      "960        1958          2008         696           0  ...               0   \n",
      "1384       1939          1950         204           0  ...               0   \n",
      "1100       1920          1950         290           0  ...               0   \n",
      "...         ...           ...         ...         ...  ...             ...   \n",
      "763        1999          1999        1163           0  ...               0   \n",
      "835        1950          1995         442           0  ...               0   \n",
      "1216       1978          1978           0           0  ...               0   \n",
      "559        2003          2004           0           0  ...               0   \n",
      "684        1998          1998           0           0  ...               0   \n",
      "\n",
      "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
      "64               0             0            1                      0   \n",
      "682              0             0            1                      0   \n",
      "960              0             0            1                      0   \n",
      "1384             0             0            1                      0   \n",
      "1100             0             0            1                      0   \n",
      "...            ...           ...          ...                    ...   \n",
      "763              0             0            1                      0   \n",
      "835              0             0            1                      0   \n",
      "1216             0             0            1                      0   \n",
      "559              0             0            1                      0   \n",
      "684              0             0            1                      0   \n",
      "\n",
      "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "64                        0                     0                     0   \n",
      "682                       0                     0                     0   \n",
      "960                       0                     0                     0   \n",
      "1384                      0                     0                     0   \n",
      "1100                      0                     0                     0   \n",
      "...                     ...                   ...                   ...   \n",
      "763                       0                     0                     0   \n",
      "835                       0                     0                     0   \n",
      "1216                      0                     0                     0   \n",
      "559                       0                     0                     0   \n",
      "684                       0                     0                     0   \n",
      "\n",
      "      SaleCondition_Normal  SaleCondition_Partial  \n",
      "64                       1                      0  \n",
      "682                      1                      0  \n",
      "960                      1                      0  \n",
      "1384                     1                      0  \n",
      "1100                     1                      0  \n",
      "...                    ...                    ...  \n",
      "763                      1                      0  \n",
      "835                      1                      0  \n",
      "1216                     1                      0  \n",
      "559                      1                      0  \n",
      "684                      1                      0  \n",
      "\n",
      "[1022 rows x 217 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/housing.csv')\n",
    "data = pd.get_dummies(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(['SalePrice'], axis=1), \n",
    "                                                    data.SalePrice, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遗传算法\n",
    "\n",
    "遗传算法是用于搜索非常大空间的全局优化技术。您可以将它们视为一种随机搜索。他们受到自然选择和繁殖的生物学机制的启发。\n",
    "\n",
    "它们在可能的解决方案群体（称为世代）中工作，其中搜索空间中的每个解决方案都表示为一些有限符号集上的有限长度字符串（染色体），然后使用目标（或适应度）函数来评估适用性每个解决方案。\n",
    "\n",
    "在特征选择方面，每条染色体将代表一个特征子集，并用二进制编码表示：1 表示“选择”给定特征，0 表示“不选择”特征。\n",
    "\n",
    "> 例如，字符串 1001 表示选择第一个和最后一个特征作为特征子集。\n",
    "\n",
    "之后，我们进行多次迭代，使用一些运算符从当前一代中创建新一代（新特征子集）可能的解决方案：\n",
    "\n",
    "* Selection：概率性地过滤掉性能不佳的解决方案，同时选择高性能的解决方案进行利用。\n",
    "* Cross Over：这是探索新解决方案和在特征之间交换信息的 GA 方式。该算子将用于随机选择染色体对，概率等于给定的交叉率。这样，我们生成了新的染色体，希望能保留前几代的良好特征。\n",
    "* Mutation：这个操作保护 GAs 免受不可恢复的良好解决方案特征的损失。它以等于非常低的给定突变率的概率更改某些染色体的符号，以恢复丢失的遗传物质。\n",
    "\n",
    "详细步骤：\n",
    "1. 用随机生成的个体初始化种群——在我们的例子中，这意味着不同的特征子集——并创建一个机器学习算法。\n",
    "2. 根据所选算法，使用您选择的评估指标评估每个特征子集的适应度。\n",
    "3. 在新种群中重现高适应度染色体（特征子集）\n",
    "4. 去除适应性差的染色体（Selection）\n",
    "5. 构建新的染色体 (crossover).\n",
    "6. 恢复丢失的特征 (mutation).\n",
    "7. 重复步骤 2-6，直到满足停止条件（例如，可以是迭代次数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeneticSelectionCV:\n",
    "\n",
    "* estimator: 用于评估特征子集适用性的模型，以及评估指标。\n",
    "cv: int, 生成器，或用于确定交叉验证拆分策略的迭代器。\n",
    "scoring: 评估指标，或者我们可以称之为评估染色体性能的适应度函数，即机器学习模型对特征子集的性能。\n",
    "max_features: 定义最大特征数量。\n",
    "n_population: 遗传算法的种群数量，表示不同的特征子集\n",
    "crossover_proba: 遗传算法的交叉操作的概率值。\n",
    "mutation_proba: 遗传算法变异操作的概率值。\n",
    "n_generations: 一个整数，描述遗传算法的代数——停止标准。\n",
    "crossover_independent_proba: 每个属性被交换的独立概率——这样我们为遗传算法的搜索提供了更大的灵活性。\n",
    "mutation_independent_proba: 每个属性被遗传算法变异的独立概率。\n",
    "n_gen_no_change: 如果最好的个体没有改变，则终止搜索所需的世代数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False  True False False False  True False False\n",
      " False False False False False  True False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=231)\n",
    "\n",
    "selection = GeneticSelectionCV(model,\n",
    "                              cv=5,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=12,\n",
    "                              n_population=120,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=50,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              n_gen_no_change=10,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# fit the GA search to our data.\n",
    "selection = selection.fit(x_train, y_train)\n",
    "\n",
    "# print the results.\n",
    "print(selection.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征重要性\n",
    "## 排列重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PassengerId': 0.21194768009370735, 'Pclass': 0.21797791804949995, 'Age': 0.20932300817769678, 'SibSp': 0.09590898245157375, 'Parch': 0.0444784277998308, 'Fare': 0.2959317585301837}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pd.read_csv('data/titanic.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(['Survived'], axis=1), \n",
    "                                                    data.Survived, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "numerical_x_train = x_train[x_train.select_dtypes([np.number]).columns].fillna(0)\n",
    "# build your model and train it.\n",
    "model = RandomForestClassifier(n_estimators=221)\n",
    "model.fit(numerical_x_train, y_train)\n",
    "\n",
    "# get the default score.\n",
    "predict_y = model.predict(numerical_x_train)\n",
    "train_auc = roc_auc_score(y_train, predict_y)\n",
    "feature_dict_scores = {}\n",
    "\n",
    "# loop over all the features\n",
    "for feature in numerical_x_train.columns:\n",
    "\n",
    "    # copy the dataset, because we want to do some permutation.\n",
    "    x_train_copy = numerical_x_train.copy().reset_index(drop=True)\n",
    "    y_train_copy = y_train.copy().reset_index(drop=True)\n",
    "    \n",
    "    # shuffle an individual feature.\n",
    "    x_train_copy[feature] = x_train_copy[feature].sample(frac=1,random_state=2022).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # make a prediction with permuted feature and calculate roc auc\n",
    "    shuff_auc = roc_auc_score(y_train_copy, model.predict(x_train_copy))\n",
    "    \n",
    "    # save the drop in dictionary.\n",
    "    feature_dict_scores[feature] = (train_auc - shuff_auc)\n",
    "    \n",
    "# print the resulting dictionary , feature => how much it drop the score.\n",
    "print(feature_dict_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习-AEFS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 19ms/step - loss: 1217.7031 - val_loss: 1169.1609\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1216.3784 - val_loss: 1168.0691\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1215.0660 - val_loss: 1166.9574\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1213.7545 - val_loss: 1165.8386\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1212.4463 - val_loss: 1164.7054\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1211.1356 - val_loss: 1163.5625\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1209.8276 - val_loss: 1162.4102\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1208.5099 - val_loss: 1161.2482\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1207.1895 - val_loss: 1160.0618\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1205.8473 - val_loss: 1158.8746\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1204.5203 - val_loss: 1157.6776\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1203.1810 - val_loss: 1156.4685\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1200.5819 - val_loss: 1155.2213\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1199.1021 - val_loss: 1153.9999\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1197.7035 - val_loss: 1152.7656\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1196.3085 - val_loss: 1151.5254\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1194.9254 - val_loss: 1150.2626\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1193.5227 - val_loss: 1149.0070\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1192.1337 - val_loss: 1147.7301\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1182.1873 - val_loss: 1146.3594\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1180.2103 - val_loss: 1145.1422\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1178.5912 - val_loss: 1143.9357\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1177.1095 - val_loss: 1142.7258\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1175.6646 - val_loss: 1141.5879\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1174.2430 - val_loss: 1140.3547\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1172.8511 - val_loss: 1139.1094\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1171.4481 - val_loss: 1137.8533\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1170.0498 - val_loss: 1136.5918\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1168.6487 - val_loss: 1135.3129\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1167.2390 - val_loss: 1134.0209\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1165.8209 - val_loss: 1132.7095\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1164.3910 - val_loss: 1131.3867\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1162.9475 - val_loss: 1130.0463\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1155.9397 - val_loss: 1128.6276\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1153.5040 - val_loss: 1127.3424\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1151.8810 - val_loss: 1126.0508\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1150.3630 - val_loss: 1124.7480\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1148.8723 - val_loss: 1123.4253\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1147.3604 - val_loss: 1122.0940\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1145.8877 - val_loss: 1120.7520\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1144.3983 - val_loss: 1119.3893\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1142.8995 - val_loss: 1118.0117\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1141.3987 - val_loss: 1116.6217\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1139.8724 - val_loss: 1115.2103\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1138.3402 - val_loss: 1113.7791\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1136.7689 - val_loss: 1112.3256\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1135.1810 - val_loss: 1110.8540\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1133.5717 - val_loss: 1109.3667\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1131.9462 - val_loss: 1107.8503\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1130.2937 - val_loss: 1103.6508\n",
      "[-0.35885394 -0.48393714  0.13383065 -0.44797233 -0.3027203   0.21518528\n",
      "  0.5562088  -0.79036325  0.4324551  -0.2206572   0.16481143  0.5448662\n",
      "  0.7880837  -0.422435    0.6202542  -0.6404837 ]\n"
     ]
    }
   ],
   "source": [
    "# import the keras library.\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "numerical_x_train = numerical_x_train.astype('float64')\n",
    "numerical_x_test = x_test[x_test.select_dtypes([np.number]).columns].fillna(0).astype('float64')\n",
    "# the dimension of the encoding layer.\n",
    "encoding_dim = 16\n",
    "\n",
    "# create the autoencoder.\n",
    "model = Sequential()\n",
    "\n",
    "# add the encoding layer.\n",
    "model.add(Dense(encoding_dim, activation='relu', input_shape=(numerical_x_train.shape[1],)))\n",
    "\n",
    "# add the output layer.\n",
    "model.add(Dense(numerical_x_train.shape[1], activation='linear'))\n",
    "\n",
    "# compile the model, you can use whatever optimizer.\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy')\n",
    "\n",
    "# fit your model to the training data.\n",
    "model.fit(numerical_x_train, numerical_x_train,\n",
    "                epochs=50,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(numerical_x_test, numerical_x_test))\n",
    "\n",
    "# get the first layer weights.\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "\n",
    "# get the feature importance.\n",
    "print(weights.sum(axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bafc338abc57834bacf3c306014ce0c45f0aeaf201b721c6f2bfe17ccf7009fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
